{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-10T10:39:59.299055Z",
     "start_time": "2025-02-10T10:39:59.293964Z"
    }
   },
   "source": [
    "PREFIJO_SAVE = \"resultados_iniciales\"\n",
    "def load_config():\n",
    "    \"\"\"\n",
    "    Carga los parámetros de configuración en un diccionario para facilitar su uso.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"num_rounds\": 10,\n",
    "        \"num_clients\": 10,\n",
    "        \"random_seed\": 42,\n",
    "        \"batch_size\": 32,\n",
    "        \"num_shadow_models\": 5,\n",
    "        \"global_model_epochs\": 10,\n",
    "        \"shadow_train_rounds\": 10,\n",
    "        \"shadow_data_fraction\": 0.01,\n",
    "        \"prob_range\": 0.1,\n",
    "        \"clients_random\": False,\n",
    "        \"fraction\": 0.1, \n",
    "        \n",
    "        # RUIDO #\n",
    "        \"aplicar_ruido\": True,\n",
    "        \"ruido_obj\": [\"gradients\"],\n",
    "        \"ruido_per\": 0.4,  # Proporción de datos afectados por ruido\n",
    "        \"noise_std\": 0.2,   # Desviación estándar del ruido\n",
    "        \"epsilon\": 1.0,     # Parámetro de privacidad diferencial\n",
    "        \"delta\": 1e-5,      # Delta para ruido gaussiano\n",
    "        \"sensitivity\": 1.0, # Sensibilidad del mecanismo de ruido\n",
    "        \"privacy_type\": \"gaussian\",  # Tipo de ruido a aplicar\n",
    "        \"selected_layers\": \"all\", # [0, -1]  # Aplica ruido a todas las capas\n",
    "\n",
    "        # LABEL FLIPPING #\n",
    "        \"label_flipping\": False,\n",
    "        \"flipping_antes\": False,\n",
    "        \"prob_flip_0\": 0.2,\n",
    "        \"prob_flip_1\": 0.2,\n",
    "        \"flip_target\": \"Slice\",\n",
    "        \n",
    "        # RESULTADOS #\n",
    "        \"property_threshold\": 0.5,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"data_file_path\": 'label_bi_10.csv',\n",
    "        \"prefijo_save\": \"resultados_iniciales\",\n",
    "    }\n",
    "\n",
    "config = load_config()"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "3bb448f0fe1ab29f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:39:59.341105Z",
     "start_time": "2025-02-10T10:39:59.303234Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, roc_curve, confusion_matrix\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tqdm\n",
    "from numpy.random import laplace, normal\n",
    "from scipy.stats import bootstrap\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)  \n",
    "\n",
    "set_seed()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "28c8288548d1c03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:39:59.346114Z",
     "start_time": "2025-02-10T10:39:59.342111Z"
    }
   },
   "source": [
    "#### LOG ####\n",
    "LOG_DIR = 'logs'\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "if not os.path.exists(config[\"prefijo_save\"]):\n",
    "    os.makedirs(config[\"prefijo_save\"])\n",
    "    \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(os.path.join(LOG_DIR, 'execution.log')),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "id": "10cc2fca338cd9cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:39:59.352233Z",
     "start_time": "2025-02-10T10:39:59.347118Z"
    }
   },
   "source": [
    "def validate_configuration():\n",
    "    \"\"\"\n",
    "    Valida las configuraciones de parámetros y asegura que las combinaciones sean coherentes.\n",
    "    \"\"\"\n",
    "    logger.info(\"Validating configuration...\")\n",
    "\n",
    "    # Informar configuraciones redundantes\n",
    "    if not config[\"label_flipping\"] and config[\"flipping_antes\"]:\n",
    "        raise ValueError(\"FLIPPING_ANTES=True no tiene sentido cuando LABEL_FLIPPING=False.\")\n",
    "\n",
    "    if not config[\"aplicar_ruido\"] and not config[\"label_flipping\"]:\n",
    "        logger.info(\"Ni ruido ni label flipping están activados. El experimento no incluye perturbaciones en los datos.\")\n",
    "\n",
    "    # Validar parámetros relacionados con ruido\n",
    "    if config[\"aplicar_ruido\"]:\n",
    "        if config[\"epsilon\"] <= 0:\n",
    "            raise ValueError(\"EPSILON debe ser mayor que 0.\")\n",
    "        if config[\"delta\"] is not None and not (0 < config[\"delta\"] < 1):\n",
    "            raise ValueError(\"DELTA debe estar entre 0 y 1 si se usa ruido gaussiano.\")\n",
    "        if config[\"sensitivity\"] <= 0:\n",
    "            raise ValueError(\"SENSITIVITY debe ser mayor que 0.\")\n",
    "        if not all(obj in [\"gradients\", \"data\"] for obj in config[\"ruido_obj\"]):\n",
    "            raise ValueError(\"RUÍDO_OBJ solo puede contener 'gradients' o 'data'.\")\n",
    "\n",
    "    # Validar parámetros relacionados con flipping\n",
    "    if config[\"label_flipping\"]:\n",
    "        if not (0 <= config[\"prob_flip_0\"] <= 1):\n",
    "            raise ValueError(\"PROB_FLIP_0 debe estar entre 0 y 1.\")\n",
    "        if not (0 <= config[\"prob_flip_1\"] <= 1):\n",
    "            raise ValueError(\"PROB_FLIP_1 debe estar entre 0 y 1.\")\n",
    "\n",
    "    logger.info(\"Configuration validation completed successfully.\")\n"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "id": "f275bdad6a1c8604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:39:59.360126Z",
     "start_time": "2025-02-10T10:39:59.353238Z"
    }
   },
   "source": [
    "#### DATA ####\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carga un archivo CSV y devuelve un DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"El archivo {file_path} no se encontró.\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df, fraction=config[\"fraction\"]):\n",
    "    \"\"\"\n",
    "    Preprocesa los datos, filtra columnas necesarias y aplica muestreo.\n",
    "    \"\"\"\n",
    "    necessary_columns = [\n",
    "        'Src IP', 'Src Port', 'Dst Port', 'Protocol', 'Flow Duration', 'Total Fwd Packet',\n",
    "        'Fwd Packet Length Std', 'ACK Flag Count', 'Fwd Seg Size Min', 'label', 'Slice'\n",
    "    ]\n",
    "    \n",
    "    df = df[necessary_columns].dropna()\n",
    "    df = df.sample(frac=fraction, random_state = SEED).reset_index(drop=True)\n",
    "\n",
    "    X = df.drop(['label', 'Slice'], axis=1)\n",
    "    y_label = df['label']\n",
    "    y_slice = df['Slice']\n",
    "\n",
    "    return X, y_label, y_slice\n",
    "\n",
    "def create_client_data(X, y_label, y_slice, config):\n",
    "    \"\"\"\n",
    "    Divide los datos para los clientes y aplica ruido o flipping si está configurado.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Características de los datos.\n",
    "        y_label (Series): Etiquetas de clasificación.\n",
    "        y_slice (Series): Propiedad objetivo.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de datos de clientes con propiedades ajustadas.\n",
    "    \"\"\"\n",
    "    num_clients = config[\"num_clients\"]  # Extraer el número de clientes correctamente\n",
    "    \n",
    "    logger.info(f\"Creating data for {num_clients} clients with security configurations\")\n",
    "    logger.info(f\"Shape de X antes de dividir clientes: {X.shape}\")\n",
    "    \n",
    "    logger.info(f\"Creating data for {num_clients} clients with security configurations\")\n",
    "\n",
    "    # Separar datos con y sin propiedad\n",
    "    X_with_property = X[y_slice == 1]\n",
    "    y_label_with_property = y_label[y_slice == 1]\n",
    "    X_without_property = X[y_slice == 0]\n",
    "    y_label_without_property = y_label[y_slice == 0]\n",
    "\n",
    "    if num_clients % 2 != 0:\n",
    "        raise ValueError(\"El número de clientes debe ser par para balancear propiedades.\")\n",
    "    \n",
    "    logger.info(f\"Shape de X con propiedad: {X_with_property.shape}, sin propiedad: {X_without_property.shape}\")\n",
    "\n",
    "    min_data_size = min(\n",
    "        len(X_with_property) // (num_clients // 2), \n",
    "        len(X_without_property) // (num_clients // 2)\n",
    "    )\n",
    "\n",
    "    client_data = []\n",
    "\n",
    "    for i in range(num_clients // 2):\n",
    "        client_data.append({\n",
    "            'X': X_with_property.iloc[i * min_data_size:(i + 1) * min_data_size],\n",
    "            'y_label': y_label_with_property.iloc[i * min_data_size:(i + 1) * min_data_size].copy(),\n",
    "            'y_slice': 1,\n",
    "            'has_property': True\n",
    "        })\n",
    "\n",
    "        client_data.append({\n",
    "            'X': X_without_property.iloc[i * min_data_size:(i + 1) * min_data_size],\n",
    "            'y_label': y_label_without_property.iloc[i * min_data_size:(i + 1) * min_data_size].copy(),\n",
    "            'y_slice': 0,\n",
    "            'has_property': False\n",
    "        })\n",
    "    logger.info(f\"Shape of client data input: {client_data[0]['X'].shape}\")\n",
    "\n",
    "    return client_data\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "id": "bb63cc478e698133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:40:00.101771Z",
     "start_time": "2025-02-10T10:39:59.361317Z"
    }
   },
   "source": [
    "#### MODELS ####\n",
    "def split_data_for_models(X, y_label, y_slice, config):\n",
    "    \"\"\"\n",
    "    Divide los datos en conjuntos para el modelo global y los modelos sombra.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): Características de los datos.\n",
    "        y_label (Series): Etiquetas de clasificación.\n",
    "        y_slice (Series): Propiedad objetivo.\n",
    "        config (dict): Configuración de parámetros.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: (Conjunto global, Conjunto shadow, Número de muestras shadow).\n",
    "    \"\"\"\n",
    "    logger.info(\"Dividiendo datos para el modelo global y los modelos sombra.\")\n",
    "\n",
    "    num_shadow_samples = int(len(X) * config['shadow_data_fraction'])\n",
    "    indices = np.arange(len(X))\n",
    "    #np.random.shuffle(indices)\n",
    "    indices = np.argsort(X.index)  # Ordena de manera fija los datos\n",
    "\n",
    "    shadow_indices = indices[:num_shadow_samples]\n",
    "    global_indices = indices[num_shadow_samples:]\n",
    "\n",
    "    X_shadow, y_label_shadow, y_slice_shadow = X.iloc[shadow_indices], y_label.iloc[shadow_indices], y_slice.iloc[shadow_indices]\n",
    "    X_global, y_label_global, y_slice_global = X.iloc[global_indices], y_label.iloc[global_indices], y_slice.iloc[global_indices]\n",
    "\n",
    "    logger.info(f\"Datos divididos: {len(X_global)} para el modelo global, {len(X_shadow)} para los modelos sombra.\")\n",
    "    \n",
    "    return (X_global, y_label_global, y_slice_global), (X_shadow, y_label_shadow, y_slice_shadow), len(X_shadow)\n",
    "\n",
    "def create_global_model(input_shape, config):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal para aprendizaje federado.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (int): Número de características de entrada.\n",
    "        config (dict): Configuración de entrenamiento.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Modelo compilado.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creando modelo global con input shape {input_shape}\")\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_shadow_model(input_shape, config):\n",
    "    \"\"\"\n",
    "    Crea un modelo sombra más simple para inferencia de propiedades.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (int): Dimensión de entrada.\n",
    "        config (dict): Configuración del modelo.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Modelo de shadow compilado.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creando modelo sombra con input shape {input_shape}\")\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def select_clients(round_num, clients_with_property, clients_without_property):\n",
    "    \"\"\"\n",
    "    Selecciona los clientes de forma determinista:\n",
    "    - En rondas pares: Se eligen clientes con la propiedad.\n",
    "    - En rondas impares: Se eligen clientes sin la propiedad.\n",
    "    \"\"\"\n",
    "    return clients_with_property if round_num % 2 == 0 else clients_without_property\n",
    "\n",
    "def initialize_clients(client_data, global_model, global_model_epochs, batch_size):\n",
    "\n",
    "    def init_client(client_id, data):\n",
    "        # Pasar el modelo global completo\n",
    "        return SimulatedFlowerClient(client_id, data, global_model, global_model_epochs, batch_size)\n",
    "\n",
    "    # Paralelizar la inicialización de los clientes\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(init_client, i, data) for i, data in enumerate(client_data)]\n",
    "        clients = [f.result() for f in futures]\n",
    "\n",
    "    return clients\n",
    "\n",
    "class SimulatedFlowerClient:\n",
    "    def __init__(self, client_id, data, global_model, config, batch_size):\n",
    "        \"\"\"\n",
    "        Inicializa un cliente simulado con sus datos y modelo en Federated Learning.\n",
    "\n",
    "        Parameters:\n",
    "            client_id (int): Identificador único del cliente.\n",
    "            data (dict): Diccionario con 'X' (features) y 'y_label' (etiquetas).\n",
    "            global_model (tf.keras.Model): Modelo central para copiar pesos.\n",
    "            config (dict): Configuración del experimento.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.client_id = client_id\n",
    "        self.X = data[\"X\"]\n",
    "        self.y_label = data[\"y_label\"]\n",
    "        self.config = config\n",
    "\n",
    "        # Inicializar el modelo copiando el global\n",
    "        self.model = tf.keras.models.clone_model(global_model)\n",
    "        self.model.set_weights(global_model.get_weights())\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        \"\"\"Devuelve los parámetros actuales del modelo del cliente.\"\"\"\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, global_weights):\n",
    "        \"\"\"\n",
    "        Entrena el modelo localmente y aplica transformaciones si es necesario.\n",
    "        \"\"\"\n",
    "        self.model.set_weights(global_weights)\n",
    "        self.model.fit(self.X, self.y_label, epochs=self.config[\"global_model_epochs\"],\n",
    "                       batch_size=self.config[\"batch_size\"], verbose=0)\n",
    "\n",
    "        updates = [new_w - old_w for new_w, old_w in zip(self.model.get_weights(), global_weights)]\n",
    "\n",
    "        # Aplicar ruido si está configurado\n",
    "        if self.config[\"aplicar_ruido\"]:\n",
    "            if \"gradients\" in self.config[\"ruido_obj\"]:\n",
    "                updates = [apply_noise_to_gradients(layer, self.config) for layer in updates]\n",
    "            if \"data\" in self.config[\"ruido_obj\"]:\n",
    "                self.X = add_noise(self.X.to_numpy(), self.config)  # Se aplica ruido a los datos\n",
    "\n",
    "        return self.model.get_weights(), len(self.X), {\"updates\": updates}\n",
    "\n",
    "    def evaluate(self, global_weights):\n",
    "        \"\"\"\n",
    "        Evalúa el modelo global en los datos locales del cliente.\n",
    "\n",
    "        Parameters:\n",
    "            global_weights (list): Pesos del modelo global.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (Loss, número de muestras, metadatos de precisión).\n",
    "        \"\"\"\n",
    "        self.model.set_weights(global_weights)\n",
    "        loss, accuracy = self.model.evaluate(self.X, self.y_label, verbose=0)\n",
    "        return loss, len(self.X), {\"accuracy\": accuracy}\n",
    "\n",
    "def train_shadow_models(X_shadow, y_label_shadow, y_slice_shadow, num_shadow_models, global_model, config):\n",
    "    \"\"\"\n",
    "    Entrena los modelos sombra usando las actualizaciones de los pesos.\n",
    "\n",
    "    Parameters:\n",
    "        X_shadow (DataFrame): Conjunto de datos para los shadow models.\n",
    "        y_label_shadow (Series): Etiquetas asociadas a X_shadow.\n",
    "        y_slice_shadow (Series): Información de propiedad para inferencia.\n",
    "        global_model (tf.keras.Model): Modelo base del entrenamiento.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de modelos sombra entrenados.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    logger.info(f\"Training {config['num_shadow_models']} shadow models prior to federated learning.\")\n",
    "\n",
    "    # Resetear índices para evitar errores de acceso\n",
    "    y_slice_shadow = y_slice_shadow.reset_index(drop=True)\n",
    "\n",
    "    # Crear modelos sombra con la misma estructura del modelo global\n",
    "    shadow_models = []\n",
    "    for i in range(config['num_shadow_models']):\n",
    "        logger.info(f\"Training shadow model {i + 1}/{config['num_shadow_models']}\")\n",
    "\n",
    "        shadow_model = tf.keras.models.clone_model(global_model)\n",
    "        shadow_model.set_weights(global_model.get_weights())\n",
    "        shadow_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Entrenar el modelo con todos los datos shadow\n",
    "        shadow_model.fit(X_shadow, y_label_shadow, epochs=config['global_model_epochs'], \n",
    "                         batch_size=config['batch_size'], verbose=0)\n",
    "        shadow_models.append(shadow_model)\n",
    "\n",
    "    logger.info(\"All shadow models trained successfully.\")\n",
    "    return shadow_models\n",
    "\n",
    "def infer_with_shadow_models(shadow_models, updates, config):\n",
    "    \"\"\"\n",
    "    Realiza inferencia usando los modelos sombra.\n",
    "    \"\"\"\n",
    "    if len(updates) == 0:\n",
    "        logger.error(\"Lista de updates está vacía. No hay actualizaciones para inferencia.\")\n",
    "        raise ValueError(\"Lista de updates está vacía. No hay actualizaciones para inferencia.\")\n",
    "\n",
    "    # Normalizar el tamaño de los updates\n",
    "    uniform_size = max([u.size for u in updates])\n",
    "    normalized_updates = [np.pad(u.flatten(), (0, uniform_size - u.size), 'constant') for u in updates]\n",
    "\n",
    "    # Tomar solo los primeros 9 valores para cada update\n",
    "    truncated_updates = np.array([u[:9] for u in normalized_updates])\n",
    "\n",
    "    # Asegurar que cada fila es una muestra de entrada con 9 características\n",
    "    flattened_updates = truncated_updates.reshape(-1, 9)\n",
    "\n",
    "    logger.debug(f\"Shape de updates normalizados: {truncated_updates.shape}\")\n",
    "    logger.debug(f\"Shape de flattened_updates: {flattened_updates.shape}\")\n",
    "\n",
    "    # Aplicar predicción a cada modelo sombra\n",
    "    probabilities = [model.predict(flattened_updates, verbose=0).flatten() for model in shadow_models]\n",
    "    \n",
    "    return np.mean(probabilities)\n",
    "def normalize_updates(client_updates):\n",
    "    \"\"\"\n",
    "    Normaliza los updates de los clientes asegurando que todos tengan la misma longitud.\n",
    "    \"\"\"\n",
    "    # Obtener el número de capas en las actualizaciones\n",
    "    num_layers = len(client_updates[0])\n",
    "    \n",
    "    # Para cada capa, encontrar el tamaño máximo de los arrays\n",
    "    max_sizes = [max([update[layer_idx].size for update in client_updates]) for layer_idx in range(num_layers)]\n",
    "    \n",
    "    # Normalizar cada capa por separado\n",
    "    normalized_updates = []\n",
    "    for update in client_updates:\n",
    "        normalized_update = []\n",
    "        for layer_idx in range(num_layers):\n",
    "            layer_update = update[layer_idx]\n",
    "            # Rellenar con ceros si es necesario\n",
    "            normalized_layer = np.pad(layer_update.flatten(), (0, max_sizes[layer_idx] - layer_update.size), 'constant')\n",
    "            normalized_update.append(normalized_layer)\n",
    "        normalized_updates.append(normalized_update)\n",
    "    \n",
    "    return normalized_updates\n",
    "\n",
    "\n",
    "def average_client_updates(client_updates):\n",
    "    \"\"\"\n",
    "    Promedia las actualizaciones de los clientes asegurándose de que todas tengan la misma longitud.\n",
    "    \"\"\"\n",
    "    if len(client_updates) == 0:\n",
    "        raise ValueError(\"La lista de client_updates está vacía. No se puede calcular el promedio.\")\n",
    "\n",
    "    # Normalizar las actualizaciones\n",
    "    normalized_updates = normalize_updates(client_updates)\n",
    "    \n",
    "    # Obtener el número de capas\n",
    "    num_layers = len(client_updates[0])\n",
    "    \n",
    "    # Promediar las actualizaciones por capa\n",
    "    averaged_updates = []\n",
    "    for layer_idx in range(num_layers):\n",
    "        # Obtener todas las actualizaciones para esta capa\n",
    "        layer_updates = [update[layer_idx] for update in normalized_updates]\n",
    "        # Promediar las actualizaciones de esta capa\n",
    "        averaged_layer = np.mean(layer_updates, axis=0)\n",
    "        averaged_updates.append(averaged_layer)\n",
    "    \n",
    "    return averaged_updates\n",
    "\n",
    "\n",
    "def custom_model(input_shape, config=None):\n",
    "    \"\"\"\n",
    "    Crea un modelo de inferencia personalizado para shadow models.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (int): Dimensión de entrada del modelo.\n",
    "        config (dict, opcional): Configuración para ajustar la arquitectura.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Modelo compilado.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creating custom shadow model with input shape {input_shape}\")\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate'] if config else 0.001),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "id": "3d4f8900b3c0e38e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:40:00.112257Z",
     "start_time": "2025-02-10T10:40:00.102808Z"
    }
   },
   "source": [
    "#### SEGURIDAD ####\n",
    "\n",
    "def apply_label_flipping(y_data, flip_target, prob_flip_0, prob_flip_1):\n",
    "    \"\"\"\n",
    "    Aplica flipping de etiquetas o propiedades basado en el parámetro flip_target.\n",
    "    \"\"\"\n",
    "    if flip_target not in [\"label\", \"Slice\"]:\n",
    "        raise ValueError(f\"Invalid flip_target: {flip_target}. Must be 'label' or 'Slice'.\")\n",
    "\n",
    "    if isinstance(y_data, pd.Series):\n",
    "        # Caso Series: se asume que el target es directamente la serie\n",
    "        target_data = y_data\n",
    "\n",
    "    elif isinstance(y_data, pd.DataFrame):\n",
    "        # Caso DataFrame: se accede a la columna específica indicada por flip_target\n",
    "        if flip_target in y_data.columns:\n",
    "            target_data = y_data[flip_target]\n",
    "        else:\n",
    "            raise KeyError(f\"Column '{flip_target}' is not found in DataFrame data.\")\n",
    "\n",
    "    else:\n",
    "        raise TypeError(f\"Unsupported data type: {type(y_data)}. Must be pandas DataFrame or Series.\")\n",
    "\n",
    "    # Flipping 0 -> 1\n",
    "    flip_0_indices = target_data[target_data == 0].index\n",
    "    num_flips_0_to_1 = int(len(flip_0_indices) * prob_flip_0)\n",
    "    flipped_0_indices = np.random.choice(flip_0_indices, num_flips_0_to_1, replace=False)\n",
    "    target_data.loc[flipped_0_indices] = 1\n",
    "\n",
    "    # Flipping 1 -> 0\n",
    "    flip_1_indices = target_data[target_data == 1].index\n",
    "    num_flips_1_to_0 = int(len(flip_1_indices) * prob_flip_1)\n",
    "    flipped_1_indices = np.random.choice(flip_1_indices, num_flips_1_to_0, replace=False)\n",
    "    target_data.loc[flipped_1_indices] = 0\n",
    "\n",
    "    logger.info(f\"Flipped {num_flips_0_to_1} entries from 0 -> 1 and {num_flips_1_to_0} from 1 -> 0.\")\n",
    "\n",
    "    return target_data\n",
    "\n",
    "\n",
    "def add_noise(data, config):\n",
    "    \"\"\"\n",
    "    Aplica ruido diferencialmente privado a los datos o actualizaciones según el tipo seleccionado.\n",
    "    \"\"\"\n",
    "    ruido_per = config[\"ruido_per\"]\n",
    "    ruido_std = config[\"noise_std\"]\n",
    "    epsilon = config[\"epsilon\"]\n",
    "    delta = config.get(\"delta\", None)\n",
    "    sensitivity = config[\"sensitivity\"]\n",
    "    privacy_type = config[\"privacy_type\"]\n",
    "\n",
    "    if not (0 <= ruido_per <= 1):\n",
    "        raise ValueError(\"ruido_per debe estar entre 0 y 1.\")\n",
    "    if epsilon <= 0:\n",
    "        raise ValueError(\"epsilon debe ser mayor que 0.\")\n",
    "    if privacy_type not in [\"gaussian\", \"laplacian\"]:\n",
    "        raise ValueError(\"privacy_type debe ser 'gaussian' o 'laplacian'.\")\n",
    "\n",
    "    num_samples = int(len(data) * ruido_per)\n",
    "    noisy_indices = np.random.choice(len(data), size=num_samples, replace=False)\n",
    "\n",
    "    if privacy_type == \"gaussian\":\n",
    "        noise_scale = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon if delta else ruido_std\n",
    "        noise = np.random.normal(0, noise_scale, size=(num_samples, data.shape[1]))\n",
    "    else:  # Laplaciano\n",
    "        noise_scale = sensitivity / epsilon\n",
    "        noise = np.random.laplace(0, noise_scale, size=(num_samples, data.shape[1]))\n",
    "\n",
    "    data_noisy = data.copy()\n",
    "    data_noisy[noisy_indices, :] += noise\n",
    "    return data_noisy\n",
    "\n",
    "def apply_noise(data, ruido_per, ruido_std, epsilon, delta, sensitivity, ruido_antes, privacy_type=\"gaussian\"):\n",
    "    \"\"\"\n",
    "    Aplica ruido con privacidad diferencial a los datos o actualizaciones.\n",
    "    \"\"\"\n",
    "    if privacy_type not in [\"gaussian\", \"laplacian\"]:\n",
    "        raise ValueError(\"privacy_type debe ser 'gaussian' o 'laplacian'.\")\n",
    "\n",
    "    return add_noise(data, ruido_per)\n",
    "\n",
    "\n",
    "def apply_noise_to_gradients(gradients, config):\n",
    "    \"\"\"\n",
    "    Aplica ruido diferencialmente privado a los gradientes antes de enviarlos al servidor en FL.\n",
    "    \n",
    "    Parameters:\n",
    "        gradients (list): Lista de arrays de gradientes por capa.\n",
    "        config (dict): Configuración con los parámetros de ruido.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de gradientes con ruido aplicado en las capas seleccionadas.\n",
    "    \"\"\"\n",
    "    epsilon = config[\"epsilon\"]\n",
    "    delta = config.get(\"delta\", None)\n",
    "    sensitivity = config[\"sensitivity\"]\n",
    "    privacy_type = config[\"privacy_type\"]\n",
    "    selected_layers = config.get(\"selected_layers\", \"all\")  # Puede ser una lista de índices o \"all\"\n",
    "\n",
    "    if epsilon <= 0:\n",
    "        raise ValueError(\"epsilon debe ser mayor que 0.\")\n",
    "\n",
    "    # Calcular la escala del ruido\n",
    "    if privacy_type == \"gaussian\":\n",
    "        noise_scale = sensitivity * np.sqrt(2 * np.log(1.25 / delta)) / epsilon\n",
    "    else:  # Laplaciano\n",
    "        noise_scale = sensitivity / epsilon\n",
    "\n",
    "    # Si \"all\", aplicar ruido a todas las capas, si no, solo a las seleccionadas\n",
    "    for i in range(len(gradients)):\n",
    "        if selected_layers == \"all\" or i in selected_layers:\n",
    "            if privacy_type == \"gaussian\":\n",
    "                noise = np.random.normal(0, noise_scale, size=gradients[i].shape)\n",
    "            else:\n",
    "                noise = np.random.laplace(0, noise_scale, size=gradients[i].shape)\n",
    "            \n",
    "            gradients[i] += noise  # Aplicar ruido\n",
    "\n",
    "    return gradients\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_flipping(data, flip_target, prob_flip_0, prob_flip_1):\n",
    "    \"\"\"\n",
    "    Aplica flipping de etiquetas o propiedades basado en configuraciones.\n",
    "    \"\"\"\n",
    "    return apply_label_flipping(data, flip_target, prob_flip_0, prob_flip_1)\n"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "id": "b2a49a38cf731cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:40:00.139954Z",
     "start_time": "2025-02-10T10:40:00.113371Z"
    }
   },
   "source": [
    "#### OUTPUTS ####\n",
    "def calculate_correct_predictions(results, config):\n",
    "    \"\"\"\n",
    "    Calcula la cantidad de predicciones correctas e incorrectas basadas en la propiedad detectada.\n",
    "    \n",
    "    Parameters:\n",
    "        results (list): Lista de resultados de la simulación.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Correctos, Incorrectos, Threshold Dinámico).\n",
    "    \"\"\"\n",
    "    correct_predictions = 0\n",
    "    incorrect_predictions = 0\n",
    "    dynamic_thresholds = calculate_dynamic_threshold(results, config)\n",
    "\n",
    "    # Ignorar las primeras tres rondas\n",
    "    for i in range(3, len(results)):\n",
    "        current_prob = results[i]['property_probability']\n",
    "        previous_prob = results[i - 1]['property_probability']\n",
    "        previous_property = results[i - 1]['has_property']\n",
    "        current_property = results[i]['has_property']\n",
    "        threshold = dynamic_thresholds[i]\n",
    "\n",
    "        # Clasificación basada en transiciones de propiedad\n",
    "        if not previous_property and not current_property:\n",
    "            is_correct = abs(current_prob - previous_prob) < threshold * 0.1\n",
    "        elif previous_property and not current_property:\n",
    "            is_correct = current_prob < previous_prob\n",
    "        elif not previous_property and current_property:\n",
    "            is_correct = current_prob > previous_prob\n",
    "        elif previous_property and current_property:\n",
    "            is_correct = abs(current_prob - previous_prob) < threshold * 0.1\n",
    "        else:\n",
    "            is_correct = False\n",
    "\n",
    "        if is_correct:\n",
    "            correct_predictions += 1\n",
    "        else:\n",
    "            incorrect_predictions += 1\n",
    "\n",
    "    total_predictions = correct_predictions + incorrect_predictions\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    logger.info(f\"Correct predictions: {correct_predictions}, Incorrect predictions: {incorrect_predictions}, Accuracy: {accuracy:.4f}\")\n",
    "    return correct_predictions, incorrect_predictions, dynamic_thresholds\n",
    "\n",
    "def plot_results(results, output_path):\n",
    "    \"\"\"\n",
    "    Genera gráficos de la evolución de la probabilidad detectada, pérdida y precisión.\n",
    "\n",
    "    Parameters:\n",
    "        results (list): Resultados de la simulación.\n",
    "        output_path (str): Directorio para guardar las imágenes.\n",
    "    \"\"\"\n",
    "    # Ignorar las primeras tres rondas para evitar ruido inicial\n",
    "    round_nums = [r['round'] for r in results][3:]\n",
    "    probabilities = [r['property_probability'] for r in results][3:]\n",
    "    thresholds = [r['threshold_used'] for r in results][3:]\n",
    "    losses = [r['loss'] for r in results][3:]\n",
    "    accuracies = [r['accuracy'] for r in results][3:]\n",
    "    property_present = [r['has_property'] for r in results][3:]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # Gráfico 1: Evolución de la probabilidad detectada vs Threshold dinámico\n",
    "    round_nums = [r['round'] for r in results][3:]\n",
    "    probabilities = [r['property_probability'] for r in results][3:]\n",
    "    losses = [r['loss'] for r in results][3:]\n",
    "    accuracies = [r['accuracy'] for r in results][3:]\n",
    "    property_present = [r['has_property'] for r in results][3:]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # Gráfico 1: Probabilidad por ronda\n",
    "    axs[0].plot(round_nums, probabilities, marker='o', color='blue', label='Property Probability')\n",
    "    for round_, prob, present in zip(round_nums, probabilities, property_present):\n",
    "        if present:\n",
    "            axs[0].scatter(round_, prob, color='red', zorder=5, label='Rounds with Property' if round_nums.index(round_) == 0 else \"\")\n",
    "    axs[0].set_xlabel('Round')\n",
    "    axs[0].set_ylabel('Property Probability')\n",
    "    axs[0].set_title('Property Probability by Round (ignoring first 3 rounds)')\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Gráfico 2: Pérdida y Precisión del modelo global\n",
    "    ax1 = axs[1]\n",
    "    ax1.plot(round_nums, losses, label='Loss', color='red', marker='x')\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('Loss', color='red')\n",
    "    ax1.tick_params(axis='y', labelcolor='red')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(round_nums, accuracies, label='Accuracy', color='blue', marker='o')\n",
    "    ax2.set_ylabel('Accuracy', color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{output_path}/probability_loss_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_combined_roc_threshold(fpr, tpr, thresholds, auc_roc, optimal_threshold, output_path):\n",
    "    \"\"\"\n",
    "    Genera una imagen con dos gráficos:\n",
    "    - Izquierda: Curva ROC.\n",
    "    - Derecha: TPR/FPR vs Threshold con umbral óptimo.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Gráfico 1: Curva ROC\n",
    "    axs[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {auc_roc:.2f})')\n",
    "    axs[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "    axs[0].set_xlabel('False Positive Rate')\n",
    "    axs[0].set_ylabel('True Positive Rate')\n",
    "    axs[0].set_title('ROC Curve')\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Gráfico 2: TPR/FPR vs Threshold\n",
    "    axs[1].plot(thresholds, tpr, label='True Positive Rate (TPR)', color='green', lw=2)\n",
    "    axs[1].plot(thresholds, fpr, label='False Positive Rate (FPR)', color='red', lw=2)\n",
    "    axs[1].axvline(optimal_threshold, color='blue', linestyle='--', label=f'Optimal Threshold ({optimal_threshold:.2f})')\n",
    "    axs[1].set_xlabel('Threshold')\n",
    "    axs[1].set_ylabel('Rate')\n",
    "    axs[1].set_title('TPR and FPR vs. Threshold')\n",
    "    axs[1].legend(loc=\"best\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{output_path}/roc_threshold.png\")\n",
    "    plt.close()\n",
    "    \n",
    "def calculate_and_log_metrics(results, config):\n",
    "    \"\"\"\n",
    "    Calcula las métricas principales y devuelve un diccionario con los resultados.\n",
    "\n",
    "    Parameters:\n",
    "        results (list): Lista de resultados de la simulación.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Diccionario de métricas, fpr, tpr, thresholds, custom_precision).\n",
    "    \"\"\"\n",
    "    y_true = [r['has_property'] for r in results][3:]  # Ignorar las 3 primeras rondas\n",
    "    y_prob = [r['property_probability'] for r in results][3:]\n",
    "    dynamic_thresholds = [r.get('threshold_used', config[\"property_threshold\"]) for r in results][3:]  # Evitar errores de key\n",
    "\n",
    "    # Clasificar usando el threshold dinámico\n",
    "    y_pred_dynamic = [1 if prob > thresh else 0 for prob, thresh in zip(y_prob, dynamic_thresholds)]\n",
    "\n",
    "    # Calcular curva ROC y encontrar el threshold óptimo\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx] if len(thresholds) > 0 else config[\"property_threshold\"]\n",
    "\n",
    "    # Clasificar usando el threshold óptimo de ROC\n",
    "    y_pred_optimal = [1 if prob > optimal_threshold else 0 for prob in y_prob]\n",
    "\n",
    "    # Calcular métricas para el threshold dinámico\n",
    "    cm_dynamic = confusion_matrix(y_true, y_pred_dynamic)\n",
    "    tn_dyn, fp_dyn, fn_dyn, tp_dyn = cm_dynamic.ravel() if cm_dynamic.shape == (2,2) else (0, 0, 0, 0)\n",
    "    precision_dyn = tp_dyn / (tp_dyn + fp_dyn) if (tp_dyn + fp_dyn) > 0 else 0\n",
    "    recall_dyn = tp_dyn / (tp_dyn + fn_dyn) if (tp_dyn + fn_dyn) > 0 else 0\n",
    "    f1_dyn = 2 * (precision_dyn * recall_dyn) / (precision_dyn + recall_dyn) if (precision_dyn + recall_dyn) > 0 else 0\n",
    "\n",
    "    # Calcular métricas para el threshold óptimo\n",
    "    cm_optimal = confusion_matrix(y_true, y_pred_optimal)\n",
    "    tn_opt, fp_opt, fn_opt, tp_opt = cm_optimal.ravel() if cm_optimal.shape == (2,2) else (0, 0, 0, 0)\n",
    "    precision_opt = tp_opt / (tp_opt + fp_opt) if (tp_opt + fp_opt) > 0 else 0\n",
    "    recall_opt = tp_opt / (tp_opt + fn_opt) if (tp_opt + fn_opt) > 0 else 0\n",
    "    f1_opt = 2 * (precision_opt * recall_opt) / (precision_opt + recall_opt) if (precision_opt + recall_opt) > 0 else 0\n",
    "\n",
    "    # Precisión basada en transiciones de probabilidad\n",
    "    correct_transitions, incorrect_transitions, _ = calculate_correct_predictions(results, config)\n",
    "    total_transitions = correct_transitions + incorrect_transitions\n",
    "    custom_precision = (correct_transitions / total_transitions) * 100 if total_transitions > 0 else 0\n",
    "\n",
    "    # Calcular intervalos de confianza\n",
    "    precision_ci_dyn = intervalo_confianza(y_pred_dynamic)\n",
    "    recall_ci_dyn = intervalo_confianza(y_true)\n",
    "    auc_ci = intervalo_confianza(y_prob)\n",
    "    f1_ci_dyn = intervalo_confianza([f1_dyn] * len(y_true))\n",
    "\n",
    "    metrics = {\n",
    "        'ROC AUC': auc_roc,\n",
    "        'Optimal Threshold': optimal_threshold,\n",
    "        'Precision (Dynamic)': precision_dyn,\n",
    "        'Recall (Dynamic)': recall_dyn,\n",
    "        'F1-Score (Dynamic)': f1_dyn,\n",
    "        'True Positive (Dynamic)': tp_dyn,\n",
    "        'False Positive (Dynamic)': fp_dyn,\n",
    "        'True Negative (Dynamic)': tn_dyn,\n",
    "        'False Negative (Dynamic)': fn_dyn,\n",
    "        'Precision (Optimal)': precision_opt,\n",
    "        'Recall (Optimal)': recall_opt,\n",
    "        'F1-Score (Optimal)': f1_opt,\n",
    "        'True Positive (Optimal)': tp_opt,\n",
    "        'False Positive (Optimal)': fp_opt,\n",
    "        'True Negative (Optimal)': tn_opt,\n",
    "        'False Negative (Optimal)': fn_opt,\n",
    "        'Custom Precision': custom_precision\n",
    "    }\n",
    "    \n",
    "    # Agregar intervalos de confianza\n",
    "    metrics.update({\n",
    "        'Precision CI (Dynamic)': f\"{precision_ci_dyn[0]:.4f} - {precision_ci_dyn[1]:.4f}\",\n",
    "        'Recall CI (Dynamic)': f\"{recall_ci_dyn[0]:.4f} - {recall_ci_dyn[1]:.4f}\",\n",
    "        'ROC AUC CI': f\"{auc_ci[0]:.4f} - {auc_ci[1]:.4f}\",\n",
    "        'F1-Score CI (Dynamic)': f\"{f1_ci_dyn[0]:.4f} - {f1_ci_dyn[1]:.4f}\"\n",
    "    })\n",
    "    \n",
    "    return metrics, fpr, tpr, thresholds, custom_precision\n",
    "\n",
    "def save_results_to_csv(results, transitions, metrics):\n",
    "    \"\"\"\n",
    "    Guarda los resultados en tres CSV:\n",
    "    - Resultados detallados por ronda.\n",
    "    - Transiciones entre rondas.\n",
    "    - Resultados finales (métricas globales).\n",
    "    \"\"\"\n",
    "    if results:\n",
    "        fieldnames = list(results[0].keys())  # Asegurar que las claves coincidan\n",
    "    else:\n",
    "        fieldnames = ['Round', 'Prediction', 'Probability', 'Clients with Property', \n",
    "                      'Clients without Property', 'Has Property', 'Loss', 'Accuracy']\n",
    "\n",
    "    # Resultados por Ronda\n",
    "    with open(f\"{PREFIJO_SAVE}/round_results.csv\", 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    # Transiciones\n",
    "    if transitions:\n",
    "        fieldnames_transitions = list(transitions[0].keys())\n",
    "        with open(f\"{PREFIJO_SAVE}/transitions.csv\", 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames_transitions)\n",
    "            writer.writeheader()\n",
    "            for t in transitions:\n",
    "                writer.writerow(t)\n",
    "    \n",
    "    # Resultados Finales\n",
    "    with open(f\"{PREFIJO_SAVE}/final_metrics.csv\", 'w', newline='') as csvfile:\n",
    "        fieldnames_metrics = list(metrics.keys())\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames_metrics)\n",
    "        writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "def calculate_dynamic_threshold(results, config, min_adjustment=config[\"prob_range\"]):\n",
    "    \"\"\"\n",
    "    Calcula un threshold dinámico basado en la evolución de la probabilidad detectada.\n",
    "\n",
    "    - Si la predicción es incorrecta, ajusta el threshold para mejorar la precisión.\n",
    "    - Usa un ajuste mínimo `min_adjustment` para evitar cambios bruscos.\n",
    "\n",
    "    Parameters:\n",
    "        results (list): Resultados de la simulación.\n",
    "        config (dict): Configuración del experimento.\n",
    "        min_adjustment (float): Valor mínimo de ajuste del threshold.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de thresholds dinámicos por ronda.\n",
    "    \"\"\"\n",
    "    thresholds = [config[\"property_threshold\"]]\n",
    "\n",
    "    for i in range(1, len(results)):\n",
    "        prev_prob = results[i - 1]['property_probability']\n",
    "        curr_prob = results[i]['property_probability']\n",
    "        actual_property = results[i]['has_property']\n",
    "        pred_property = results[i]['prediction']\n",
    "\n",
    "        # Ajuste basado en errores\n",
    "        if pred_property != actual_property:\n",
    "            if pred_property:  # Falso positivo, threshold debe subir\n",
    "                new_threshold = min(thresholds[-1] + min_adjustment, 1.0)\n",
    "            else:  # Falso negativo, threshold debe bajar\n",
    "                new_threshold = max(thresholds[-1] - min_adjustment, 0.0)\n",
    "        else:\n",
    "            # Ajustar suavemente basado en la evolución de la probabilidad\n",
    "            if abs(curr_prob - prev_prob) > min_adjustment:\n",
    "                new_threshold = (curr_prob + prev_prob) / 2\n",
    "            else:\n",
    "                new_threshold = thresholds[-1]\n",
    "\n",
    "        thresholds.append(new_threshold)\n",
    "\n",
    "    return thresholds\n",
    "\n",
    "def plot_noisy_vs_clean_accuracy(noisy_results, clean_results, output_path):\n",
    "    \"\"\"\n",
    "    Compara la precisión de FL con y sin ruido en un solo gráfico.\n",
    "    \"\"\"\n",
    "    rounds = range(len(noisy_results))\n",
    "    noisy_acc = [r['accuracy'] for r in noisy_results]\n",
    "    clean_acc = [r['accuracy'] for r in clean_results]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(rounds, noisy_acc, label='Con Ruido', color='red')\n",
    "    plt.plot(rounds, clean_acc, label='Sin Ruido', color='blue')\n",
    "    plt.xlabel(\"Rondas\")\n",
    "    plt.ylabel(\"Precisión\")\n",
    "    plt.title(\"Impacto del Ruido en la Precisión de FL\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_path}/noisy_vs_clean_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def analyze_probability_transitions(results, config):\n",
    "    \"\"\"\n",
    "    Analiza las transiciones de probabilidad entre rondas usando filtrado dinámico.\n",
    "\n",
    "    Parameters:\n",
    "        results (list): Resultados de la simulación.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de transiciones clasificadas.\n",
    "    \"\"\"\n",
    "    transitions = []\n",
    "    probabilities = [r['property_probability'] for r in results][3:]\n",
    "    rounds = [r['round'] for r in results][3:]\n",
    "\n",
    "    # Filtrar valores extremos\n",
    "    prob_mean = np.mean(probabilities)\n",
    "    prob_std = np.std(probabilities)\n",
    "    lower_bound = prob_mean - 2 * prob_std\n",
    "    upper_bound = prob_mean + 2 * prob_std\n",
    "    filtered_probs = [p if lower_bound <= p <= upper_bound else prob_mean for p in probabilities]\n",
    "\n",
    "    min_prob, max_prob = min(filtered_probs), max(filtered_probs)\n",
    "    range_value = max_prob - min_prob if max_prob > min_prob else 1\n",
    "    significant_move = range_value * config[\"prob_range\"]\n",
    "\n",
    "    for i in range(1, len(filtered_probs)):\n",
    "        prev_prob = filtered_probs[i - 1]\n",
    "        curr_prob = filtered_probs[i]\n",
    "        diff = curr_prob - prev_prob\n",
    "        transition = \"stable\"\n",
    "\n",
    "        if abs(diff) > significant_move:\n",
    "            transition = \"increase\" if diff > 0 else \"decrease\"\n",
    "\n",
    "        transitions.append({\n",
    "            'round': rounds[i],\n",
    "            'prev_probability': prev_prob,\n",
    "            'current_probability': curr_prob,\n",
    "            'transition': transition\n",
    "        })\n",
    "\n",
    "    logger.info(f\"Transitions analyzed: {len(transitions)} processed.\")\n",
    "    return transitions\n",
    "\n",
    "def intervalo_confianza(data, confidence_level=0.95, n_resamples=1000):\n",
    "    \"\"\"\n",
    "    Calcula el intervalo de confianza usando bootstrap.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Verificar si los datos son válidos\n",
    "    if np.all(data == data[0]):  # Si todos los valores son iguales\n",
    "        logger.warning(\"Los datos son degenerados (todos los valores son iguales).\")\n",
    "\n",
    "        return (data[0], data[0])  # Retorna el mismo valor como intervalo\n",
    "    \n",
    "    if np.isnan(data).any() or np.isinf(data).any():  # Si hay valores inválidos\n",
    "        raise ValueError(\"Los datos contienen valores NaN o infinitos.\")\n",
    "    \n",
    "    # Calcular el intervalo de confianza\n",
    "    res = bootstrap((data,), np.mean, confidence_level=confidence_level, n_resamples=n_resamples)\n",
    "    return res.confidence_interval.low, res.confidence_interval.high\n"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "e6861ed7a278fbbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:40:00.153298Z",
     "start_time": "2025-02-10T10:40:00.140959Z"
    }
   },
   "source": [
    "#### EXPERIMENT ####\n",
    "def simulated_federated_learning(clients, shadow_models, global_model, config):\n",
    "    \"\"\"\n",
    "    Simula el aprendizaje federado con clientes seleccionados y shadow models.\n",
    "\n",
    "    Parameters:\n",
    "        clients (list): Lista de clientes en FL.\n",
    "        shadow_models (list): Modelos sombra entrenados.\n",
    "        global_model (tf.keras.Model): Modelo central.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        list: Resultados de cada ronda de entrenamiento.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting simulated federated learning with {config['num_rounds']} rounds\")\n",
    "    results = []\n",
    "\n",
    "    clients_with_property = [client for client in clients if client.data['has_property']]\n",
    "    clients_without_property = [client for client in clients if not client.data['has_property']]\n",
    "\n",
    "    logger.info(f\"{len(clients_with_property)} clients have the property.\")\n",
    "    logger.info(f\"{len(clients_without_property)} clients do not have the property.\")\n",
    "\n",
    "    for round_num in tqdm.tqdm(range(1, config['num_rounds'] + 1), desc=\"Federated Learning Progress\"):\n",
    "        logger.info(f\"Starting round {round_num}\")\n",
    "        \n",
    "        # Selección de clientes\n",
    "        use_property_clients = random.choice([True, False]) if config['clients_random'] else (round_num % 2 == 0)\n",
    "        selected_clients = clients_with_property if use_property_clients else clients_without_property\n",
    "\n",
    "        logger.info(f\"Training {len(selected_clients)} selected clients...\")\n",
    "\n",
    "        # Obtener pesos actuales del modelo global\n",
    "        global_weights = global_model.get_weights()\n",
    "        client_weights = []\n",
    "        client_updates = []\n",
    "\n",
    "        # Entrenar clientes y recolectar actualizaciones\n",
    "        for client in selected_clients:\n",
    "            w, _, update_info = client.fit(global_weights)\n",
    "            client_weights.append(w)\n",
    "            client_updates.append(update_info['updates'][:9])\n",
    "            \n",
    "        # Promediar pesos y actualizaciones\n",
    "        averaged_weights = [np.mean(layer, axis=0) for layer in zip(*client_weights)]\n",
    "        global_model.set_weights(averaged_weights)\n",
    "        averaged_updates = average_client_updates(client_updates)\n",
    "        \n",
    "        # Inferencia de los modelos sombra\n",
    "        property_prob = infer_with_shadow_models(shadow_models, averaged_updates, config)\n",
    "\n",
    "        # Calcular el threshold dinámico\n",
    "        dynamic_thresholds = calculate_dynamic_threshold(results, config)\n",
    "        threshold_value = dynamic_thresholds[min(round_num - 1, len(dynamic_thresholds) - 1)]\n",
    "        is_property_detected = property_prob > threshold_value\n",
    "\n",
    "        # Evaluación del modelo global en todos los clientes\n",
    "        total_loss, total_accuracy, total_samples = 0, 0, 0\n",
    "        for client in clients:\n",
    "            loss, num_samples, metrics = client.evaluate(global_model.get_weights())\n",
    "            total_loss += loss * num_samples\n",
    "            total_accuracy += metrics['accuracy'] * num_samples\n",
    "            total_samples += num_samples\n",
    "        \n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_accuracy = total_accuracy / total_samples\n",
    "\n",
    "        # Almacenar resultados\n",
    "        results.append({\n",
    "            'round': round_num,\n",
    "            'property_probability': property_prob,\n",
    "            'has_property': use_property_clients,\n",
    "            'prediction': is_property_detected,\n",
    "            'threshold_used': threshold_value,\n",
    "            'clients_with_property': len(clients_with_property) if use_property_clients else 0,\n",
    "            'clients_without_property': len(clients_without_property) if not use_property_clients else 0,\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': avg_accuracy\n",
    "        })\n",
    "\n",
    "        logger.info(f\"Round {round_num} completed. Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}, Property Prob: {property_prob:.4f}, Threshold: {threshold_value:.4f}\")\n",
    "\n",
    "    logger.info(\"Federated learning simulation completed.\")\n",
    "    return results\n",
    "def run_experiment_with_noise(client_data, shadow_models, config):\n",
    "    \"\"\"\n",
    "    Ejecuta la simulación de federated learning con ruido y genera métricas y visualizaciones.\n",
    "\n",
    "    Parameters:\n",
    "        client_data (list): Datos de clientes usados en el experimento.\n",
    "        shadow_models (list): Modelos sombra entrenados.\n",
    "        config (dict): Configuración del experimento.\n",
    "\n",
    "    Returns:\n",
    "        list: Resultados de la simulación con ruido.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running federated learning simulation WITH noise\")\n",
    "\n",
    "    # Reinicializar modelo global para que el entrenamiento con ruido sea independiente\n",
    "    global_model = create_global_model(client_data[0]['X'].shape[1], config)\n",
    "\n",
    "    # Aplicar la configuración de ruido\n",
    "    config[\"aplicar_ruido\"] = True\n",
    "\n",
    "    # Reinicializar clientes con la nueva configuración (para que apliquen ruido en fit())\n",
    "    clients = initialize_clients(client_data, global_model, config, batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # Ejecutar federated learning con ruido\n",
    "    noisy_results = simulated_federated_learning(clients, shadow_models, global_model, config)\n",
    "\n",
    "    # Guardar resultados y métricas\n",
    "    logger.info(\"Analyzing probability transitions (noisy)\")\n",
    "    transitions_noisy = analyze_probability_transitions(noisy_results, config)\n",
    "\n",
    "    logger.info(\"Calculating evaluation metrics (noisy)\")\n",
    "    metrics_noisy, fpr_noisy, tpr_noisy, thresholds_noisy, _ = calculate_and_log_metrics(noisy_results, config)\n",
    "\n",
    "    save_results_to_csv(noisy_results, transitions_noisy, metrics_noisy)\n",
    "\n",
    "    plot_results(noisy_results, config[\"prefijo_save\"])\n",
    "    plot_combined_roc_threshold(fpr_noisy, tpr_noisy, thresholds_noisy, metrics_noisy['ROC AUC'], \n",
    "                                metrics_noisy['Optimal Threshold'], config[\"prefijo_save\"])\n",
    "\n",
    "    return noisy_results\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta la simulación de federated learning con shadow models.\n",
    "    \"\"\"\n",
    "    # Paso 0: Validar configuración de parámetros\n",
    "    validate_configuration()\n",
    "\n",
    "    # Paso 1: Cargar y preprocesar datos\n",
    "    df = load_data(config['data_file_path'])\n",
    "    X, y_label, y_slice = preprocess_data(df, config['fraction'])\n",
    "\n",
    "    # Paso 2: Dividir datos para modelo global y modelos sombra\n",
    "    (X_global, y_label_global, y_slice_global), (X_shadow, y_label_shadow, y_slice_shadow), _ = split_data_for_models(\n",
    "        X, y_label, y_slice, config\n",
    "    )\n",
    "\n",
    "    # Paso 3: Crear datos para los clientes con opciones de ruido y flipping antes del entrenamiento\n",
    "    logger.info(\"Creating client data with configured security options\")\n",
    "    client_data = create_client_data(X_global, y_label_global, y_slice_global, config)\n",
    "\n",
    "    # Paso 4: Crear e inicializar modelo global\n",
    "    logger.info(\"Initializing global model\")\n",
    "    global_model = create_global_model(client_data[0]['X'].shape[1], config)\n",
    "\n",
    "    # Inicializar clientes simulados\n",
    "    clients = initialize_clients(client_data, global_model, config, batch_size=config[\"batch_size\"])\n",
    "\n",
    "    # Paso 5: Entrenar modelos sombra \n",
    "    logger.info(\"Training shadow models prior to federated learning\")\n",
    "    shadow_models = train_shadow_models(\n",
    "        X_shadow, y_label_shadow, y_slice_shadow, config['num_shadow_models'], global_model, config\n",
    "    )\n",
    "\n",
    "    # Paso 6: Ejecutar experimento sin ruido\n",
    "    logger.info(\"Running federated learning simulation WITHOUT noise\")\n",
    "    config[\"aplicar_ruido\"] = False\n",
    "    clean_results = simulated_federated_learning(clients, shadow_models, global_model, config)\n",
    "\n",
    "    # Guardar y visualizar resultados sin ruido\n",
    "    logger.info(\"Analyzing probability transitions (clean)\")\n",
    "    transitions_clean = analyze_probability_transitions(clean_results, config)\n",
    "\n",
    "    logger.info(\"Calculating evaluation metrics (clean)\")\n",
    "    metrics_clean, fpr_clean, tpr_clean, thresholds_clean, _ = calculate_and_log_metrics(clean_results, config)\n",
    "\n",
    "    save_results_to_csv(clean_results, transitions_clean, metrics_clean)\n",
    "    plot_results(clean_results, config[\"prefijo_save\"])\n",
    "    plot_combined_roc_threshold(fpr_clean, tpr_clean, thresholds_clean, metrics_clean['ROC AUC'],\n",
    "                                metrics_clean['Optimal Threshold'], config[\"prefijo_save\"])\n",
    "\n",
    "    # Paso 7: Ejecutar experimento con ruido si está configurado\n",
    "    if config[\"aplicar_ruido\"]:\n",
    "        noisy_results = run_experiment_with_noise(client_data, shadow_models, config)\n",
    "\n",
    "        # Comparar precisión entre ejecución con y sin ruido\n",
    "        logger.info(\"Plotting noisy vs clean accuracy impact\")\n",
    "        plot_noisy_vs_clean_accuracy(noisy_results, clean_results, config[\"prefijo_save\"])\n",
    "\n",
    "    logger.info(\"Federated learning simulation completed\")"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "id": "bd3a3dbcc20718a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:42:25.833067Z",
     "start_time": "2025-02-10T10:40:00.154302Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 11:40:00,155 - __main__ - INFO - Validating configuration...\n",
      "2025-02-10 11:40:00,156 - __main__ - INFO - Configuration validation completed successfully.\n",
      "2025-02-10 11:40:01,174 - __main__ - INFO - Dividiendo datos para el modelo global y los modelos sombra.\n",
      "2025-02-10 11:40:01,180 - __main__ - INFO - Datos divididos: 61096 para el modelo global, 617 para los modelos sombra.\n",
      "2025-02-10 11:40:01,181 - __main__ - INFO - Creating client data with configured security options\n",
      "2025-02-10 11:40:01,181 - __main__ - INFO - Creating data for 10 clients with security configurations\n",
      "2025-02-10 11:40:01,183 - __main__ - INFO - Shape de X antes de dividir clientes: (61096, 9)\n",
      "2025-02-10 11:40:01,183 - __main__ - INFO - Creating data for 10 clients with security configurations\n",
      "2025-02-10 11:40:01,188 - __main__ - INFO - Shape de X con propiedad: (29200, 9), sin propiedad: (31896, 9)\n",
      "2025-02-10 11:40:01,190 - __main__ - INFO - Shape of client data input: (5840, 9)\n",
      "2025-02-10 11:40:01,191 - __main__ - INFO - Initializing global model\n",
      "2025-02-10 11:40:01,191 - __main__ - INFO - Creando modelo global con input shape 9\n",
      "2025-02-10 11:40:01,436 - __main__ - INFO - Training shadow models prior to federated learning\n",
      "2025-02-10 11:40:01,436 - __main__ - INFO - Training 5 shadow models prior to federated learning.\n",
      "2025-02-10 11:40:01,436 - __main__ - INFO - Training shadow model 1/5\n",
      "2025-02-10 11:40:02,842 - __main__ - INFO - Training shadow model 2/5\n",
      "2025-02-10 11:40:04,212 - __main__ - INFO - Training shadow model 3/5\n",
      "2025-02-10 11:40:05,513 - __main__ - INFO - Training shadow model 4/5\n",
      "2025-02-10 11:40:06,809 - __main__ - INFO - Training shadow model 5/5\n",
      "2025-02-10 11:40:08,113 - __main__ - INFO - All shadow models trained successfully.\n",
      "2025-02-10 11:40:08,114 - __main__ - INFO - Running federated learning simulation WITHOUT noise\n",
      "2025-02-10 11:40:08,114 - __main__ - INFO - Starting simulated federated learning with 10 rounds\n",
      "2025-02-10 11:40:08,114 - __main__ - INFO - 5 clients have the property.\n",
      "2025-02-10 11:40:08,115 - __main__ - INFO - 5 clients do not have the property.\n",
      "Federated Learning Progress:   0%|          | 0/10 [00:00<?, ?it/s]2025-02-10 11:40:08,116 - __main__ - INFO - Starting round 1\n",
      "2025-02-10 11:40:08,116 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:40:26,722 - __main__ - INFO - Round 1 completed. Loss: 0.0281, Accuracy: 0.9988, Property Prob: 0.8475, Threshold: 0.5000\n",
      "Federated Learning Progress:  10%|█         | 1/10 [00:18<02:47, 18.61s/it]2025-02-10 11:40:26,723 - __main__ - INFO - Starting round 2\n",
      "2025-02-10 11:40:26,723 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:40:43,688 - __main__ - INFO - Round 2 completed. Loss: 0.0227, Accuracy: 0.9994, Property Prob: 0.8639, Threshold: 0.5000\n",
      "Federated Learning Progress:  20%|██        | 2/10 [00:35<02:21, 17.64s/it]2025-02-10 11:40:43,688 - __main__ - INFO - Starting round 3\n",
      "2025-02-10 11:40:43,689 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:40:56,564 - __main__ - INFO - Round 3 completed. Loss: 0.0056, Accuracy: 0.9994, Property Prob: 0.8649, Threshold: 0.5000\n",
      "Federated Learning Progress:  30%|███       | 3/10 [00:48<01:48, 15.47s/it]2025-02-10 11:40:56,564 - __main__ - INFO - Starting round 4\n",
      "2025-02-10 11:40:56,564 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:41:09,226 - __main__ - INFO - Round 4 completed. Loss: 0.0036, Accuracy: 0.9996, Property Prob: 0.8664, Threshold: 0.6000\n",
      "Federated Learning Progress:  40%|████      | 4/10 [01:01<01:26, 14.36s/it]2025-02-10 11:41:09,226 - __main__ - INFO - Starting round 5\n",
      "2025-02-10 11:41:09,226 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:41:22,799 - __main__ - INFO - Round 5 completed. Loss: 0.0038, Accuracy: 0.9996, Property Prob: 0.8666, Threshold: 0.6000\n",
      "Federated Learning Progress:  50%|█████     | 5/10 [01:14<01:10, 14.08s/it]2025-02-10 11:41:22,800 - __main__ - INFO - Starting round 6\n",
      "2025-02-10 11:41:22,801 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:41:35,418 - __main__ - INFO - Round 6 completed. Loss: 0.0149, Accuracy: 0.9996, Property Prob: 0.8646, Threshold: 0.7000\n",
      "Federated Learning Progress:  60%|██████    | 6/10 [01:27<00:54, 13.58s/it]2025-02-10 11:41:35,418 - __main__ - INFO - Starting round 7\n",
      "2025-02-10 11:41:35,422 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:41:48,211 - __main__ - INFO - Round 7 completed. Loss: 0.0032, Accuracy: 0.9996, Property Prob: 0.8667, Threshold: 0.7000\n",
      "Federated Learning Progress:  70%|███████   | 7/10 [01:40<00:39, 13.32s/it]2025-02-10 11:41:48,212 - __main__ - INFO - Starting round 8\n",
      "2025-02-10 11:41:48,212 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:42:00,661 - __main__ - INFO - Round 8 completed. Loss: 0.0037, Accuracy: 0.9996, Property Prob: 0.8657, Threshold: 0.8000\n",
      "Federated Learning Progress:  80%|████████  | 8/10 [01:52<00:26, 13.05s/it]2025-02-10 11:42:00,662 - __main__ - INFO - Starting round 9\n",
      "2025-02-10 11:42:00,663 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:42:13,322 - __main__ - INFO - Round 9 completed. Loss: 0.0022, Accuracy: 0.9996, Property Prob: 0.8651, Threshold: 0.8000\n",
      "Federated Learning Progress:  90%|█████████ | 9/10 [02:05<00:12, 12.93s/it]2025-02-10 11:42:13,324 - __main__ - INFO - Starting round 10\n",
      "2025-02-10 11:42:13,324 - __main__ - INFO - Training 5 selected clients...\n",
      "2025-02-10 11:42:25,370 - __main__ - INFO - Round 10 completed. Loss: 0.0025, Accuracy: 0.9996, Property Prob: 0.8664, Threshold: 0.9000\n",
      "Federated Learning Progress: 100%|██████████| 10/10 [02:17<00:00, 13.73s/it]\n",
      "2025-02-10 11:42:25,372 - __main__ - INFO - Federated learning simulation completed.\n",
      "2025-02-10 11:42:25,372 - __main__ - INFO - Analyzing probability transitions (clean)\n",
      "2025-02-10 11:42:25,373 - __main__ - INFO - Transitions analyzed: 6 processed.\n",
      "2025-02-10 11:42:25,373 - __main__ - INFO - Calculating evaluation metrics (clean)\n",
      "2025-02-10 11:42:25,375 - __main__ - INFO - Correct predictions: 3, Incorrect predictions: 4, Accuracy: 0.4286\n",
      "2025-02-10 11:42:25,378 - __main__ - WARNING - Los datos son degenerados (todos los valores son iguales).\n",
      "2025-02-10 11:42:25,743 - __main__ - INFO - Federated learning simulation completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T10:42:25.838244Z",
     "start_time": "2025-02-10T10:42:25.835871Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7b2522fbc8bf73c0",
   "outputs": [],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
